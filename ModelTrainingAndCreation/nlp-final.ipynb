{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-10T10:53:00.651990Z",
     "iopub.status.busy": "2024-12-10T10:53:00.651576Z",
     "iopub.status.idle": "2024-12-10T10:53:43.012525Z",
     "shell.execute_reply": "2024-12-10T10:53:43.010963Z",
     "shell.execute_reply.started": "2024-12-10T10:53:00.651954Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fasttext in /opt/conda/lib/python3.10/site-packages (0.9.3)\n",
      "Requirement already satisfied: pybind11>=2.2 in /opt/conda/lib/python3.10/site-packages (from fasttext) (2.13.6)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from fasttext) (70.0.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from fasttext) (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Install Necessary Libraries\n",
    "!pip install fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T10:53:43.015845Z",
     "iopub.status.busy": "2024-12-10T10:53:43.015465Z",
     "iopub.status.idle": "2024-12-10T10:53:43.463958Z",
     "shell.execute_reply": "2024-12-10T10:53:43.462800Z",
     "shell.execute_reply.started": "2024-12-10T10:53:43.015811Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Step 2: Import Libraries\n",
    "import pandas as pd\n",
    "import fasttext\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T10:53:43.465999Z",
     "iopub.status.busy": "2024-12-10T10:53:43.465354Z",
     "iopub.status.idle": "2024-12-10T10:53:43.494479Z",
     "shell.execute_reply": "2024-12-10T10:53:43.493171Z",
     "shell.execute_reply.started": "2024-12-10T10:53:43.465962Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "file_path = '/kaggle/input/setsss/dataset.csv'  # Update with your dataset location\n",
    "df = pd.read_csv(file_path)\n",
    "another_file = '/kaggle/input/food-ingredients-and-allergens/food_ingredients_and_allergens.csv'\n",
    "new_df = pd.read_csv(another_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Preprocess Data for Allergen Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T10:53:43.497075Z",
     "iopub.status.busy": "2024-12-10T10:53:43.496696Z",
     "iopub.status.idle": "2024-12-10T10:53:43.523277Z",
     "shell.execute_reply": "2024-12-10T10:53:43.521994Z",
     "shell.execute_reply.started": "2024-12-10T10:53:43.497036Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def preprocess_for_allergens(df):\n",
    "    # Fill missing values with 'None'\n",
    "    df.fillna('None', inplace=True)\n",
    "\n",
    "    # Convert all text to lowercase\n",
    "    for col in df.columns:\n",
    "        df[col] = df[col].str.lower()\n",
    "    \n",
    "    # Combine ingredient-related fields into one column for training\n",
    "    df['combined_text'] = df['Main Ingredient'] + ' ' + df['Sweetener'] + ' ' + df['Fat/Oil'] + ' ' + df['Seasoning']\n",
    "    \n",
    "    # Simplify labels for allergen presence\n",
    "    df['Allergens'] = df['Allergens'].apply(\n",
    "        lambda x: '__label__contains' if x != 'none' else '__label__does_not_contain'\n",
    "    )\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = preprocess_for_allergens(df)\n",
    "\n",
    "new_df = preprocess_for_allergens(new_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T10:53:43.525436Z",
     "iopub.status.busy": "2024-12-10T10:53:43.525040Z",
     "iopub.status.idle": "2024-12-10T10:53:43.551610Z",
     "shell.execute_reply": "2024-12-10T10:53:43.550424Z",
     "shell.execute_reply.started": "2024-12-10T10:53:43.525383Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Food Product</th>\n",
       "      <th>Main Ingredient</th>\n",
       "      <th>Sweetener</th>\n",
       "      <th>Fat/Oil</th>\n",
       "      <th>Seasoning</th>\n",
       "      <th>Allergens</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>combined_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>almond cookies</td>\n",
       "      <td>almonds</td>\n",
       "      <td>sugar</td>\n",
       "      <td>butter</td>\n",
       "      <td>flour</td>\n",
       "      <td>__label__contains</td>\n",
       "      <td>contains</td>\n",
       "      <td>almonds sugar butter flour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>almond cookies</td>\n",
       "      <td>almonds</td>\n",
       "      <td>sugar</td>\n",
       "      <td>butter</td>\n",
       "      <td>flour</td>\n",
       "      <td>__label__contains</td>\n",
       "      <td>contains</td>\n",
       "      <td>almonds sugar butter flour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chicken noodle soup</td>\n",
       "      <td>chicken broth</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>salt</td>\n",
       "      <td>__label__contains</td>\n",
       "      <td>contains</td>\n",
       "      <td>chicken broth none none salt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chicken noodle soup</td>\n",
       "      <td>chicken broth</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>salt</td>\n",
       "      <td>__label__contains</td>\n",
       "      <td>contains</td>\n",
       "      <td>chicken broth none none salt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cheddar cheese</td>\n",
       "      <td>cheese</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>salt</td>\n",
       "      <td>__label__contains</td>\n",
       "      <td>contains</td>\n",
       "      <td>cheese none none salt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>lemon bars</td>\n",
       "      <td>lemon juice</td>\n",
       "      <td>sugar</td>\n",
       "      <td>butter</td>\n",
       "      <td>flour, eggs</td>\n",
       "      <td>__label__contains</td>\n",
       "      <td>contains</td>\n",
       "      <td>lemon juice sugar butter flour, eggs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>pecan pie</td>\n",
       "      <td>pecans</td>\n",
       "      <td>sugar</td>\n",
       "      <td>butter</td>\n",
       "      <td>corn syrup</td>\n",
       "      <td>__label__contains</td>\n",
       "      <td>contains</td>\n",
       "      <td>pecans sugar butter corn syrup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>zucchini bread</td>\n",
       "      <td>zucchini</td>\n",
       "      <td>sugar</td>\n",
       "      <td>butter</td>\n",
       "      <td>cinnamon, nuts</td>\n",
       "      <td>__label__contains</td>\n",
       "      <td>contains</td>\n",
       "      <td>zucchini sugar butter cinnamon, nuts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>banana bread</td>\n",
       "      <td>bananas</td>\n",
       "      <td>sugar</td>\n",
       "      <td>butter</td>\n",
       "      <td>cinnamon, nuts</td>\n",
       "      <td>__label__contains</td>\n",
       "      <td>contains</td>\n",
       "      <td>bananas sugar butter cinnamon, nuts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>hawaiian pizza</td>\n",
       "      <td>pizza dough</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>pineapple, ham</td>\n",
       "      <td>__label__contains</td>\n",
       "      <td>contains</td>\n",
       "      <td>pizza dough none none pineapple, ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>399 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Food Product Main Ingredient Sweetener Fat/Oil       Seasoning  \\\n",
       "0         almond cookies         almonds     sugar  butter           flour   \n",
       "1         almond cookies         almonds     sugar  butter           flour   \n",
       "2    chicken noodle soup   chicken broth      none    none            salt   \n",
       "3    chicken noodle soup   chicken broth      none    none            salt   \n",
       "4         cheddar cheese          cheese      none    none            salt   \n",
       "..                   ...             ...       ...     ...             ...   \n",
       "394           lemon bars     lemon juice     sugar  butter     flour, eggs   \n",
       "395            pecan pie          pecans     sugar  butter      corn syrup   \n",
       "396       zucchini bread        zucchini     sugar  butter  cinnamon, nuts   \n",
       "397         banana bread         bananas     sugar  butter  cinnamon, nuts   \n",
       "398       hawaiian pizza     pizza dough      none    none  pineapple, ham   \n",
       "\n",
       "             Allergens Prediction                         combined_text  \n",
       "0    __label__contains   contains            almonds sugar butter flour  \n",
       "1    __label__contains   contains            almonds sugar butter flour  \n",
       "2    __label__contains   contains          chicken broth none none salt  \n",
       "3    __label__contains   contains          chicken broth none none salt  \n",
       "4    __label__contains   contains                 cheese none none salt  \n",
       "..                 ...        ...                                   ...  \n",
       "394  __label__contains   contains  lemon juice sugar butter flour, eggs  \n",
       "395  __label__contains   contains        pecans sugar butter corn syrup  \n",
       "396  __label__contains   contains  zucchini sugar butter cinnamon, nuts  \n",
       "397  __label__contains   contains   bananas sugar butter cinnamon, nuts  \n",
       "398  __label__contains   contains  pizza dough none none pineapple, ham  \n",
       "\n",
       "[399 rows x 8 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Save Preprocessed Data for FastText\n",
    "MODEL TRAINED WITH ONLY OUR DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T10:53:43.553369Z",
     "iopub.status.busy": "2024-12-10T10:53:43.553027Z",
     "iopub.status.idle": "2024-12-10T10:53:43.568336Z",
     "shell.execute_reply": "2024-12-10T10:53:43.567219Z",
     "shell.execute_reply.started": "2024-12-10T10:53:43.553328Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_file = '/kaggle/working/fasttext_train_allergen.txt'\n",
    "with open(train_file, 'w') as f:\n",
    "    for i, row in df.iterrows():\n",
    "        f.write(f\"{row['Allergens']} {row['combined_text']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6&7: Training model and saving it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T10:53:43.570789Z",
     "iopub.status.busy": "2024-12-10T10:53:43.570030Z",
     "iopub.status.idle": "2024-12-10T10:53:45.103815Z",
     "shell.execute_reply": "2024-12-10T10:53:45.102636Z",
     "shell.execute_reply.started": "2024-12-10T10:53:43.570592Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 0M words\n",
      "Number of words:  80\n",
      "Number of labels: 2\n",
      "Progress: 100.0% words/sec/thread:   63004 lr:  0.000000 avg.loss:  0.465180 ETA:   0h 0m 0s\n"
     ]
    }
   ],
   "source": [
    "model = fasttext.train_supervised(train_file, epoch=25, lr=0.1, wordNgrams=2, dim=100)\n",
    "\n",
    "model.save_model(\"/kaggle/working/allergen_detection_model.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 8: Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T10:53:45.105278Z",
     "iopub.status.busy": "2024-12-10T10:53:45.104994Z",
     "iopub.status.idle": "2024-12-10T10:53:45.123489Z",
     "shell.execute_reply": "2024-12-10T10:53:45.122109Z",
     "shell.execute_reply.started": "2024-12-10T10:53:45.105250Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 85.83%\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, df):\n",
    "    correct, total = 0, 0\n",
    "    for i, row in df.iterrows():\n",
    "        prediction = model.predict(row['combined_text'])[0][0]\n",
    "        if prediction == row['Allergens']:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "    accuracy = correct / total\n",
    "    return accuracy\n",
    "\n",
    "accuracy = evaluate_model(model, df)\n",
    "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 9: Test with New Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T10:53:45.125177Z",
     "iopub.status.busy": "2024-12-10T10:53:45.124786Z",
     "iopub.status.idle": "2024-12-10T10:53:45.139679Z",
     "shell.execute_reply": "2024-12-10T10:53:45.138299Z",
     "shell.execute_reply.started": "2024-12-10T10:53:45.125143Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dish 'tree seeds' is classified as: __label__contains\n"
     ]
    }
   ],
   "source": [
    "def predict_allergen(model, text):\n",
    "    prediction = model.predict(text.lower())\n",
    "    return prediction[0][0]  # Return the predicted label\n",
    "\n",
    "# Example Usage\n",
    "new_dish = \"tree seeds\"\n",
    "result = predict_allergen(model, new_dish)\n",
    "print(f\"The dish '{new_dish}' is classified as: {result}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T10:53:45.143812Z",
     "iopub.status.busy": "2024-12-10T10:53:45.143212Z",
     "iopub.status.idle": "2024-12-10T10:53:46.749408Z",
     "shell.execute_reply": "2024-12-10T10:53:46.748202Z",
     "shell.execute_reply.started": "2024-12-10T10:53:45.143760Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 0M words\n",
      "Number of words:  340\n",
      "Number of labels: 2\n",
      "Progress: 100.0% words/sec/thread:  324521 lr:  0.000000 avg.loss:  0.234678 ETA:   0h 0m 0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Model Accuracy: 99.23%\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Combine Old and New Datasets\n",
    "combined_df = pd.concat([df, new_df], ignore_index=True)\n",
    "\n",
    "# Step 2: Save the Combined Dataset for FastText\n",
    "combined_train_file = '/kaggle/working/combined_fasttext_train.txt'\n",
    "with open(combined_train_file, 'w') as f:\n",
    "    for i, row in combined_df.iterrows():\n",
    "        f.write(f\"{row['Allergens']} {row['combined_text']}\\n\")\n",
    "\n",
    "# Step 3: Retrain the Model\n",
    "model = fasttext.train_supervised(input=combined_train_file, epoch=25, lr=0.1, wordNgrams=2, dim=100)\n",
    "\n",
    "# Step 4: Save the Retrained Model\n",
    "model.save_model(\"/kaggle/working/allergen_detection_model_combined.bin\")\n",
    "\n",
    "# Step 5: Evaluate the New Model\n",
    "accuracy = evaluate_model(model, combined_df)  # Reuse evaluation function\n",
    "print(f\"Combined Model Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retraining with even bigger dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T10:53:46.750743Z",
     "iopub.status.busy": "2024-12-10T10:53:46.750405Z",
     "iopub.status.idle": "2024-12-10T10:53:47.473651Z",
     "shell.execute_reply": "2024-12-10T10:53:47.472298Z",
     "shell.execute_reply.started": "2024-12-10T10:53:46.750713Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 0M words\n",
      "Number of words:  341\n",
      "Number of labels: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After retraining, the dish 'Rice' is classified as: __label__does_not_contain\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100.0% words/sec/thread:  325587 lr:  0.000000 avg.loss:  0.223015 ETA:   0h 0m 0s\n"
     ]
    }
   ],
   "source": [
    "test_text = \"Rice\"\n",
    "result = model.predict(test_text.lower())\n",
    "\n",
    "# Step 2: Add Explicit Non-Allergen Examples for \"Chicken\"\n",
    "additional_data = [\n",
    "    '__label__does_not_contain chicken',\n",
    "    '__label__does_not_contain plain chicken',\n",
    "    '__label__does_not_contain chicken broth'\n",
    "]\n",
    "\n",
    "# Step 3: Append to Training File\n",
    "with open(combined_train_file, 'a') as f:\n",
    "    for line in additional_data:\n",
    "        f.write(f\"{line}\\n\")\n",
    "\n",
    "# Step 4: Retrain the Model\n",
    "model = fasttext.train_supervised(input=combined_train_file, epoch=25, lr=0.1, wordNgrams=2, dim=100)\n",
    "\n",
    "# Step 5: Retest with \"Chicken\"\n",
    "result = model.predict(test_text.lower())\n",
    "print(f\"After retraining, the dish '{test_text}' is classified as: {result[0][0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T10:53:47.476358Z",
     "iopub.status.busy": "2024-12-10T10:53:47.475451Z",
     "iopub.status.idle": "2024-12-10T10:54:30.126854Z",
     "shell.execute_reply": "2024-12-10T10:54:30.125060Z",
     "shell.execute_reply.started": "2024-12-10T10:53:47.476306Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tabulate in /opt/conda/lib/python3.10/site-packages (0.9.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tabulate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T10:54:30.129384Z",
     "iopub.status.busy": "2024-12-10T10:54:30.128985Z",
     "iopub.status.idle": "2024-12-10T10:54:44.978135Z",
     "shell.execute_reply": "2024-12-10T10:54:44.976808Z",
     "shell.execute_reply.started": "2024-12-10T10:54:30.129347Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the list of ingredients (comma-separated):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Dairy, Peanuts\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected Allergens: peanuts, dairy\n",
      "Updated Ingredients: plant-based milk, sunflower seed butter\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load Substitution Dataset\n",
    "substitution_file = '/kaggle/input/replacements/substitute_dataset.csv'  # Update with your file path\n",
    "substitution_df = pd.read_csv(substitution_file)\n",
    "\n",
    "# Convert to a dictionary for quick lookup\n",
    "substitution_map = dict(zip(substitution_df['Allergen'].str.lower(), substitution_df['Substitute Food Item'].str.lower()))\n",
    "\n",
    "# Step 2: Detect Allergens (Dummy Function for Simplicity - Replace with Model Integration)\n",
    "def detect_allergens(ingredients, allergen_list):\n",
    "    \"\"\"\n",
    "    Dummy allergen detection function.\n",
    "    Replace this with actual model integration for detecting allergens.\n",
    "    \n",
    "    Parameters:\n",
    "        ingredients (list): List of ingredient names.\n",
    "        allergen_list (list): List of possible allergens.\n",
    "    \n",
    "    Returns:\n",
    "        list: Detected allergens present in the ingredients.\n",
    "    \"\"\"\n",
    "    detected = []\n",
    "    for allergen in allergen_list:\n",
    "        for ingredient in ingredients:\n",
    "            if allergen in ingredient.lower():\n",
    "                detected.append(allergen)\n",
    "    return list(set(detected))  # Return unique allergens\n",
    "\n",
    "# Step 3: Replace Allergens with Substitutes\n",
    "def replace_allergens_with_substitutes(ingredients, detected_allergens, substitution_map):\n",
    "    updated_ingredients = ingredients[:]\n",
    "    for allergen in detected_allergens:\n",
    "        if allergen in substitution_map:\n",
    "            substitute = substitution_map[allergen]\n",
    "            updated_ingredients = [\n",
    "                substitute if allergen in ingredient.lower() else ingredient \n",
    "                for ingredient in updated_ingredients\n",
    "            ]\n",
    "    return updated_ingredients\n",
    "\n",
    "# Step 4: Interactive User Input\n",
    "def main():\n",
    "    print(\"Enter the list of ingredients (comma-separated):\")\n",
    "    user_input = input().strip()\n",
    "    dish_ingredients = [ingredient.strip().lower() for ingredient in user_input.split(\",\")]\n",
    "\n",
    "    # List of possible allergens (keys from the substitution map)\n",
    "    allergen_list = list(substitution_map.keys())\n",
    "\n",
    "    # Detect allergens in the dish\n",
    "    detected_allergens = detect_allergens(dish_ingredients, allergen_list)\n",
    "    if detected_allergens:\n",
    "        print(f\"Detected Allergens: {', '.join(detected_allergens)}\")\n",
    "        \n",
    "        # Replace allergens with substitutes\n",
    "        updated_ingredients = replace_allergens_with_substitutes(dish_ingredients, detected_allergens, substitution_map)\n",
    "        print(f\"Updated Ingredients: {', '.join(updated_ingredients)}\")\n",
    "    else:\n",
    "        print(\"No allergens detected in the provided ingredients.\")\n",
    "\n",
    "# Run the interactive program\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T10:54:44.980155Z",
     "iopub.status.busy": "2024-12-10T10:54:44.979769Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# Create a zip file\n",
    "shutil.make_archive(\"/kaggle/working/allergen_detection_model_combined.bin\", 'zip', \"/kaggle/working\")\n",
    "\n",
    "# The zip file will be saved as 'allergen_model_files.zip' in /kaggle/working\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 3310996,
     "sourceId": 5759769,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6269423,
     "sourceId": 10154663,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6269462,
     "sourceId": 10154721,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30804,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
